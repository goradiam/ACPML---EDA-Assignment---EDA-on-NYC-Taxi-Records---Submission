{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goradiam/ACPML---EDA-Assignment---EDA-on-NYC-Taxi-Records---Submission/blob/main/Tree_Models_Guided_Model_Building_%5Bexercise%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tree Models - Guided Model Building**\n",
        "\n",
        "In this session, you will build a decision tree model using `scikit-learn` to predict hotel booking cancellations. The target variable for this task is `booking status`.\n",
        "\n",
        "Some of the tasks you will perform include:\n",
        "* Exploring and understanding the dataset\n",
        "* Data cleaning and preprocessing\n",
        "* Encoding categorical variables\n",
        "* Creating a train-test split\n",
        "* Training a predictive model to classify the `booking status`\n",
        "* Evaluating and visualising the model's performance\n",
        "\n",
        "Let's get started by importing the necessary libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "vDo9OBlOYu0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.tree import plot_tree\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "qNarquRQZG8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1 Data Preparation**"
      ],
      "metadata": {
        "id": "tE-glhk8zs_o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1 Load and inspect the data**\n",
        "\n",
        "Load the data and inspect it to get a sense of the data and to check for the presence of missing values, incorrect formatting, and other anomalies."
      ],
      "metadata": {
        "id": "ozbmLTNMzcsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"booking.csv\")"
      ],
      "metadata": {
        "id": "fCl3bAfXZtUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "wIrYqkcSZ75u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "PtbX5BbbaAc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2 Clean and preprocess the data**\n",
        "\n",
        "Clean the data; be sure to handle missing values, formatting issues, and any other anomalies that may hamper model building and training"
      ],
      "metadata": {
        "id": "UgHgMXmazquy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE ###\n"
      ],
      "metadata": {
        "id": "8aPV6xOPbOlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Depending on the output, you might decide to drop rows/columns or fill missing values.\n",
        "# Example (fill with median for numerical columns):\n",
        "# for col in df.columns:\n",
        "#     if df[col].dtype in ['int64', 'float64']:\n",
        "#         df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "# Example (drop rows with any missing values):\n",
        "# df.dropna(inplace=True)\n",
        "\n",
        "# Check for duplicate rows\n",
        "print(df.duplicated().sum())\n",
        "\n",
        "# Example (drop duplicate rows):\n",
        "# df.drop_duplicates(inplace=True)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "LSIwxX1xiChf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.3 Encoding Categorical Variables**\n",
        "\n",
        "As the data contains some categorical entries which we do want to consider for our analysis, we may need to perform one-hot encoding on these categorical columns. You may use `pd.get_dummies()` to achieve this. Be sure to convert the values to numeric type before proceeding.\n",
        "\n",
        "**Note:** Not all models require this step, please consult the documentation of the model you are using to see if encoding is necessary.\n"
      ],
      "metadata": {
        "id": "TEcsjMV1k-D6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE ###\n",
        "\n",
        "# Identify categorical columns (you might need to adjust this based on your data)\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Perform one-hot encoding\n",
        "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# Convert values to numeric type (get_dummies usually handles this, but it's good to be explicit if needed)\n",
        "df_encoded = df_encoded.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Handle any new missing values that might have been introduced by coercion (e.g., drop rows)\n",
        "df_encoded.dropna(inplace=True)\n",
        "\n",
        "# Display the first few rows of the encoded dataframe\n",
        "print(df_encoded.head())\n"
      ],
      "metadata": {
        "id": "uoOmvkYB5Ab8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2 Model Building**"
      ],
      "metadata": {
        "id": "iepxb0P5gGq0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1 Create the train-test splits**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "You may use `sklearn.model_selection.train_test_split()` to create a train-test split of your data. We will not be performing cross-validation and hence a cross-validation split is not necessary. We recommend an $80:20$ split."
      ],
      "metadata": {
        "id": "in8kSTES2a-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "metadata": {
        "id": "kmLTUUZnDVh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Define features (X) and target (y)\n",
        "X = df_encoded.drop('booking status', axis=1)\n",
        "y = df_encoded['booking status']\n",
        "\n",
        "# Create the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "8-U_6de8h-Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**2.2 Train the model**\n",
        "\n",
        "You can use `sklearn.tree.DecisionTreeClassifier()` to build a classification model.\n",
        "\n",
        "Train this model using only the training split of the data.\n"
      ],
      "metadata": {
        "id": "fXzP_s1I212E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "metadata": {
        "id": "NtxxDBl-DmLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Initialize the Decision Tree Classifier\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "dt_model.fit(X_train, y_train)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "5NaS3NMvh9CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**2.3 Feature Importance**\n",
        "\n",
        "You can use the `feature_importances_` attribute of the trained model to get the importance score for each feature.\n",
        "\n",
        "Visualise the feature importances to understand which features contribute the most to the decision-making process."
      ],
      "metadata": {
        "id": "ar8IzYofL9vT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "metadata": {
        "id": "1ec8yoR5E4zM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Get feature importances\n",
        "feature_importances = dt_model.feature_importances_\n",
        "\n",
        "# Create a DataFrame for visualization\n",
        "feature_importance_df = pd.DataFrame({'feature': X.columns, 'importance': feature_importances})\n",
        "\n",
        "# Sort features by importance\n",
        "feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
        "\n",
        "# Visualize feature importances\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='importance', y='feature', data=feature_importance_df)\n",
        "plt.title('Feature Importances')\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "tnZI0OFIh7iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**2.4 Hyperparameter Tuning**\n",
        "\n",
        "You can use `GridSearchCV()` from  `sklearn.model_selection` to find the best combination of hyperparameters for your decision tree classifier.\n",
        "\n",
        "Fit the grid search using only the training split of the data.\n",
        "\n",
        "**Hyperparameters to Tune:**\n",
        "\n",
        "**max_depth:** Controls the tree's maximum depth.\n",
        "\n",
        "**min_samples_split:** Minimum samples required to split a node.\n",
        "\n",
        "**min_samples_leaf:** Minimum samples required at a leaf node.\n",
        "\n",
        "**criterion:** Split quality measure. 'gini' (Gini impurity) or 'entropy' (information gain).\n",
        "\n",
        "`GridSearchCV()` automatically fits the best model with the optimal hyperparameters and stores it in `grid_search.best_estimator_`.\n",
        "\n",
        "You can directly access this `best_estimator_` attribute and use it for further predictions, evaluation, or visualisation."
      ],
      "metadata": {
        "id": "Yy8v75XMMSHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "metadata": {
        "id": "E6eS_lvdGsNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gTJX8UOyh4P9"
      }
    },
    {
      "source": [
        "# Define the hyperparameter grid to search\n",
        "param_grid = {\n",
        "    'max_depth': [None, 5, 10, 15, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters and best estimator\n",
        "best_params = grid_search.best_params_\n",
        "best_dt_model = grid_search.best_estimator_\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Best Decision Tree Model:\", best_dt_model)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Meu6FKRxh3uX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**2.5 Visualising the Decision Tree**\n",
        "\n",
        "After training your `DecisionTreeClassifier`, you can visualise the tree to better understand how the model is making decisions based on the features. You can use `plot_tree` from `sklearn.tree` to visualise the structure of the decision tree.\n",
        "\n",
        "To keep the visualisation simple and focused, we can  limit the depth of the tree to show only the first 3 levels (`max_depth=3`), making it easier to interpret the key decision points without overwhelming the viewer."
      ],
      "metadata": {
        "id": "yPcywP3YOXBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "metadata": {
        "id": "ESTiDtaYD2iE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Visualize the best decision tree\n",
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(best_dt_model,\n",
        "          feature_names=X.columns.tolist(),\n",
        "          class_names=['Not Cancelled', 'Cancelled'], # Assuming 0 is not cancelled and 1 is cancelled\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          max_depth=3) # Limit depth for better visualization\n",
        "plt.title('Best Decision Tree Classifier (max_depth=3)')\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "fAq0J1Azh1PK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Visualising a decision tree allows us to understand how the model makes decisions and which features are most important in predicting the target variable. It shows the rules the model uses to classify data, helping to explain its behavior.\n",
        "\n",
        "This can also reveal if the model is too complex, which might indicate overfitting, or too simple, which might suggest it isn't learning enough from the data. By examining the tree, we can gain insights into the patterns in the data, helping to refine the model for better performance."
      ],
      "metadata": {
        "id": "lGP8HB82RjB5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.6 Make predictions**\n",
        "\n",
        "Make predictions using the trained model. Make separate predictions on the training and test sets."
      ],
      "metadata": {
        "id": "tCPWAVj43Oeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "metadata": {
        "id": "tzjEOm0HJrd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Make predictions on the training set\n",
        "y_train_pred = best_dt_model.predict(X_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_test_pred = best_dt_model.predict(X_test)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "csIWICSHhzpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3 Model Evaluation**"
      ],
      "metadata": {
        "id": "8WoSJl_h3gLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**3.1  ROC Curve**\n",
        "\n",
        "You can evaluate the performance of your classification model using the ROC (Receiver Operating Characteristic) curve. This helps visualise the trade-off between sensitivity (true positive rate) and specificity (false positive rate) across different thresholds, which is especially important in medical prediction tasks where minimising false negatives is critical.\n"
      ],
      "metadata": {
        "id": "4yJkScWslE9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "metadata": {
        "id": "sQGmvrDaTgb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Get predicted probabilities for the positive class (booking status = 1)\n",
        "y_prob = best_dt_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "\n",
        "# Calculate ROC AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random guess')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "9wB5lOnNhxLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**3.2 Classification Report**\n",
        "\n",
        "Use the classification report to evaluate model performance with key metrics like precision, recall, and F1-score. It helps assess how well the model handles each class, especially in imbalanced datasets."
      ],
      "metadata": {
        "id": "I0Xqn_R8XEf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE ###\n"
      ],
      "metadata": {
        "id": "D19iB45cSrV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Generate classification report\n",
        "class_report = classification_report(y_test, y_test_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(class_report)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ladEYIGshvEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **4 Using Other Models & Techniques**\n",
        "\n",
        "You've built a decision tree model and tuned it. Now, try stronger models like Random Forest (ensemble of trees) and XGBoost (boosting method).\n",
        "\n",
        "For tuning, try other techniques outside of a grid search. Consider using `RandomizedSearchCV()` for speed or perform manual tuning if you understand the model well.\n",
        "\n",
        "Also, you can enhance evaluation with tools like the precision-recall curve to better assess performance."
      ],
      "metadata": {
        "id": "6Cl57u4LlbA7"
      }
    }
  ]
}